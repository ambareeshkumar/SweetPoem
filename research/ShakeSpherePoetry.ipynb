{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset  \n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shakespeare dataset has been downloaded and saved to ./Data/shakespeare\\shakespeare.txt\n"
     ]
    }
   ],
   "source": [
    "def download_shakespeare_data(folder_path, file_name=\"shakespeare.txt\"):\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    with open(file_path, \"w\", encoding='utf-8') as file:\n",
    "        file.write(response.text)\n",
    "    \n",
    "    print(f\"Shakespeare dataset has been downloaded and saved to {file_path}\")\n",
    "\n",
    "folder_path = \"./Data/shakespeare\"\n",
    "\n",
    "download_shakespeare_data(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cleaned and saved to 'cleaned_shakespeare.txt'\n"
     ]
    }
   ],
   "source": [
    "# import string\n",
    "\n",
    "# allowed_chars = set(string.ascii_letters + string.digits + string.punctuation + string.whitespace)\n",
    "\n",
    "# with open('./Data/shakespeare/shakespeare.txt', 'r',  encoding='utf-8') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# # Filter the dataset\n",
    "# cleaned_text = ''.join(c for c in text if c in allowed_chars)\n",
    "\n",
    "# # Write the cleaned dataset to a new file\n",
    "# with open('./Data/shakespeare/cleaned_shakespeare.txt', 'w') as file:\n",
    "#     file.write(cleaned_text)\n",
    "\n",
    "# print(\"Dataset cleaned and saved to 'cleaned_shakespeare.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 characters of Shakespeare's text.\n",
      "Number of unique characters: 80\n",
      "Sample mapping: [('\\n', 0), (' ', 1), ('!', 2), ('(', 3), (')', 4), ('*', 5), (',', 6), ('-', 7), ('.', 8), ('0', 9)]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = \"./Data/shakespeare/shakespeare.txt\"\n",
    "with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text = text[:100000]\n",
    "print(f\"Loaded {len(text)} characters of Shakespeare's text.\")\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "\n",
    "print(f\"Number of unique characters: {len(chars)}\")\n",
    "print(f\"Sample mapping: {list(char_to_idx.items())[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 99900\n"
     ]
    }
   ],
   "source": [
    "text_indices = [char_to_idx[char] for char in text]\n",
    "\n",
    "# Create sequences and targets\n",
    "sequence_length = 100\n",
    "sequences = []\n",
    "targets = []\n",
    "\n",
    "for i in range(0, len(text_indices) - sequence_length):\n",
    "    seq = text_indices[i:i + sequence_length]\n",
    "    target = text_indices[i + 1:i + sequence_length + 1]\n",
    "    sequences.append(seq)\n",
    "    targets.append(target)\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "targets = np.array(targets)\n",
    "\n",
    "print(f\"Number of sequences: {len(sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sequences tensor: torch.Size([99900, 100])\n",
      "Shape of targets tensor: torch.Size([99900, 100])\n"
     ]
    }
   ],
   "source": [
    "sequences = torch.tensor(sequences, dtype=torch.long)\n",
    "targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "print(f\"Shape of sequences tensor: {sequences.shape}\")\n",
    "print(f\"Shape of targets tensor: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence batch shape: torch.Size([64, 100])\n",
      "Target batch shape: torch.Size([64, 100])\n"
     ]
    }
   ],
   "source": [
    "class ShakeSphereDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.sequences[index], self.targets[index]\n",
    "\n",
    "\n",
    "shakesphereDF = ShakeSphereDataset(sequences=sequences, targets=targets)\n",
    "dataloader = DataLoader(dataset = shakesphereDF, batch_size = 64, shuffle = True)\n",
    "\n",
    "for seq, tgt in dataloader:\n",
    "    print(f\"Sequence batch shape: {seq.shape}\")\n",
    "    print(f\"Target batch shape: {tgt.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LstmModel(\n",
      "  (embedding): Embedding(80, 128)\n",
      "  (lstm): LSTM(128, 256, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=80, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LstmModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(LstmModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# Parameters\n",
    "vocab_size = len(chars)\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "\n",
    "model = LstmModel(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.4414\n",
      "Epoch [2/20], Loss: 0.6550\n",
      "Epoch [3/20], Loss: 0.2705\n",
      "Epoch [4/20], Loss: 0.1861\n",
      "Epoch [5/20], Loss: 0.1629\n",
      "Epoch [6/20], Loss: 0.1503\n",
      "Epoch [7/20], Loss: 0.1424\n",
      "Epoch [8/20], Loss: 0.1366\n",
      "Epoch [9/20], Loss: 0.1322\n",
      "Epoch [10/20], Loss: 0.1290\n",
      "Epoch [11/20], Loss: 0.1264\n",
      "Epoch [12/20], Loss: 0.1238\n",
      "Epoch [13/20], Loss: 0.1219\n",
      "Epoch [14/20], Loss: 0.1203\n",
      "Epoch [15/20], Loss: 0.1189\n",
      "Epoch [16/20], Loss: 0.1173\n",
      "Epoch [17/20], Loss: 0.1165\n",
      "Epoch [18/20], Loss: 0.1153\n",
      "Epoch [19/20], Loss: 0.1143\n",
      "Epoch [20/20], Loss: 0.1135\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20  # You can adjust the number of epochs\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)  # (batch_size, sequence_length, vocab_size)\n",
    "        \n",
    "        # Reshape outputs to (batch_size * sequence_length, vocab_size)\n",
    "        outputs = outputs.view(-1, vocab_size)\n",
    "        \n",
    "        # Reshape targets to (batch_size * sequence_length)\n",
    "        targets = targets.reshape(-1)\n",
    "        \n",
    "        # Check shapes\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "torch.save(model.state_dict(), './Model/lstm_shakespeare.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "Oh world i am waiting still,\n",
      "\n",
      "After a forwall of my side,\n",
      "\n",
      "And those that said I could not love you dearer,\n",
      "\n",
      "Yet then my judgement knew no reason why,\n",
      "\n",
      "My most full flame should afterwards burn clearer,\n",
      "\n",
      "But reckoning time, who\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_text, char_to_idx, idx_to_char, length=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    input_sequence = torch.tensor([char_to_idx[c] for c in start_text if c in char_to_idx], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    generated_text = start_text\n",
    "    \n",
    "    for _ in range(length):\n",
    "        output = model(input_sequence)\n",
    "\n",
    "        output = output[:, -1, :] / temperature\n",
    "        probabilities = F.softmax(output, dim=-1).squeeze()\n",
    "        \n",
    "        predicted_idx = torch.multinomial(probabilities, 1).item()\n",
    "\n",
    "        predicted_char = idx_to_char[predicted_idx]\n",
    "        \n",
    "        generated_text += predicted_char\n",
    "        \n",
    "        predicted_idx_tensor = torch.tensor([predicted_idx], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        input_sequence = torch.cat([input_sequence, predicted_idx_tensor], dim=1)\n",
    "        input_sequence = input_sequence[:, 1:]\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "# Load the model if needed\n",
    "model.load_state_dict(torch.load('./Model/lstm_shakespeare.pth'))\n",
    "model.to(device)\n",
    "\n",
    "# Generate text\n",
    "start_text = \"Oh world i am waiting still\"\n",
    "print(len(start_text))\n",
    "generated_text = generate_text(model, start_text, char_to_idx, idx_to_char, length=200)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
